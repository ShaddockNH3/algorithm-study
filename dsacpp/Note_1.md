# 第一章 绪论
## 01A1-1.计算

## 01A1-2.绳索计算机
例1：
输入：任给直线l及其上一点A
输出：经过A做l的一条垂线
思路：
此处利用一个有12个绳结的绳索，然后利用3+4+5=12，从A点出去沿着绳子数4个绳结，然后任意方向沿着A出去拉3个绳结，最后让另外五个绳结绷紧，这样就得到了A的垂线

## 01A1-3.尺规计算机


## 01A2-1.算法
计算=信息处理
借助某种工具，遵照一定规则，以明确而机械的形式进行
计算模型=计算机=信息处理工具

## 01A2-2.有穷性
例如冰雹猜想，可以写出程序，但其未必是算法

## 01A2-3.什么是好算法
效率：速度尽可能快；存储空间尽可能少


## 01B1-1.性能测度
数据结构和算法：DSA
测度：
1）引入理想、同意、分层次的尺子
2）运用改尺子，去测量DSA

## 01B1-2.问题规模
算法分析：
1.正确性，证明一个DSA是正确的
2.==成本==：运行时间+所需存储空间（时间成本和空间成本）

观察：问题实例的==规模==，往往是决定计算成本的因素
通常：规模接近，计算成本也接近；规模扩大，计算成本亦上升

## 01B1-3.最坏情况
==特定算法+不同实例==
![[Pasted image 20240708210415.png]]
==max==
![[Pasted image 20240708210713.png]]

## 01B1-4.理想模型
多个算法？
![[Pasted image 20240708211020.png]]
做一个理想的，虚拟的实验
图灵机模型！

## 01B2-1.图灵机
Turing Marchine
Tape：
Alphabet：
Head：
State：
Transition Function：
q，代表图灵机所处状态；c，读写头当前对应字符
d，在当前单元格时输入；L/R，向左向右移动；p，将状态从q转变为p
h，停机

## 01B2-2.图灵机实例
利用图灵机进行二进制非负整数+1
![[Pasted image 20240708212341.png]]
因为可能会成为算法的一部分，所以必须要复位
规范~接口

## 01B3-1.BAM模型
Random acess mechine
寄存器顺序编号R[0],R[1]......
基本操作：
![[Pasted image 20240708213019.png]]

## 01B3-2.BAM:Floor
功能：向下取整
![[Pasted image 20240708213321.png]]
（goto 2）

给出了一把尺子，能够列出具体的表的长度来进行衡量

## C.渐行复杂度
## 01C1-1.主流长远
大O记号相当于直尺上的刻度，定性和定量之间适度集中
“好读书不求甚解；每有会意，便废寝忘食”
更多看重DSA的潜力和长远方面，不要过多注意其细微的不足
采取渐进分析法，问题规模足够大后，计算成本如何增长
即
需执行的基本操作次数：T(n)
需占用的存储单元数：S(n)  //通常可不考虑

## 01C1-2. 大O记号
上界：
T(n)=O(f(n)) iff 存在c>0, 当n>>2后, 有T(n)<c·f(n)
常系数可以忽略
低次项可忽略

下界：
![[Pasted image 20240709135325.png]]

θ，算是中间
![[Pasted image 20240709135421.png]]
双方界定

## 01C2-1. 高效解
1. ==常数复杂度O(1)==，从理论上讲，2023^2023也是O（1），
	O(1)复杂度不包含转向（循环、调用、递归）,必须顺序执行，即为O(1)
2. ==对数（对数多项式）复杂度O(logn)==
	 ![[Pasted image 20240709140400.png]]

## 01C2-2. 有效解
3. 多项式复杂度
	![[Pasted image 20240709140717.png]] 以上事实上就是已经令人满意的算法了
	 n^c
此刻度为可解的问题，再往下就是难解的问题

## 01C3-1. 难解
4. ==指数复杂度==
	 多项式可以作为指数的下界，反过来，指数可以作为多项式的上界
	 由于计算成本增加极快，通常被认为是不可忍受的
![[Pasted image 20240709141300.png]]

## 01C3-2. 2−Subset
![[Pasted image 20240709141338.png]]
直觉算法：
逐一枚举S的每一个子集
np-complete
不存在可以在多项式时间内回答此问题的算法
除非多加条件

## 01C4. 增长速度
![[Pasted image 20240709142239.png]]

## 01D1-1. 算法分析
如何运用工具对DSA进行分析
==去粗存精==
最重要的：goto
复杂度分析
迭代：级数求和
递归：递归跟踪+递推方程
猜测+验证


## 01D1-2. 级数
1. 算术级数
	 与末项平方同阶
2. 幂方级数
	 比幂次高出一阶
	 ![[Pasted image 20240709142907.png]]
3. 几何级数
	 与末项同阶，注意事实上O(2^n)=O(2^(n+1))
4. 收敛级数
	 总合不会超过某个上界，即O(1)
5. 未必收敛的级数
	 调和级数，logn
	 对数级数，log(n!)=nlogn
	 对数级数log1+log2+......+logn

## 01D2-1. 循环
循环vs级数

==（待会儿再看看）==

## 01D2-2. 实例：非极端元素+起泡排序

非极端元素：
给定一个互不相同的序列找出一个不是最大也不是最小的数
事实上只要选前三个数，然后去掉最大和最小的就行了，这样的算法事实上永远都是O(1)

冒泡排序则是一个O(n^2)的算法
思路是扫描交换
```
#include<iostream>
using namespace std;

void bubble(int arr[],int n) {
	for (bool sorted = false;sorted = !sorted;n--) {
		for (int i = 0;i < n-1;i++) {
			if (arr[i] > arr[i + 1]) {
				swap(arr[i], arr[i + 1]);
				sorted = false;
			}
		}
	}
}

void test_bubble() {
	int arr[10] = { 10,8,9,7,6,5,4,3,2,1 };
	bubble(arr, 10);
	for (int i = 0;i < 10;i++) {
		cout << arr[i] << endl;
	}
}

int main() {
	test_bubble();
	return 0;
}
```
这个有点难理解，大概意思就是说在我执行`sorted = !sorted`这个语句的时候，由于cpp特性，当sorted刚开始为false时，其会被反转为true，并且进行进行条件判断，为true，那么继续执行；而当sorted是true的时候，其被反转为false，然后条件判断，由于是false，所以跳出循环
这段代码后面肯定得改，因为这种代码不易于维护之类的，而且还难理解

## 01D2-2-1. 正确性的证明
算法的有穷性？
不变性：经过k轮扫描交换，最大的k个元素必然就位
单调性：经k论扫描交换后，问题规模缩减至n-k
正确性：经至多n趟扫描，算法必然终止 ，而且能给出正确答案

## 01D3-1. 封底估算-1
封底估算
抓住主要矛盾

## 01D3-1. 封底估算-2
一天，是10^5秒
三生三世，10^10秒
![[Pasted image 20240709153400.png]]


## 01E1-1. 迭代与递归
在时间复杂度上，抓住最重要的那块东西，即O(n)
在空间复杂度上，不计入输入，占用的内存是O(2)
```
int sum_arr(int arr[], int n) {
	int sum = 0;
	for (int i = 0;i < n;i++) {
		sum += arr[i];
	}
	return sum;
}
```

## 01E1-2. 减而治之
![[Pasted image 20240709154832.png]]

Decrease and conquer

## 01E1-3. 递归跟踪
直观形象，仅适用于简单的递归
为了求解一个规模为n的问题，逐步拆解为规模为n-1，为n-2，......，2，1
![[Pasted image 20240709155329.png]]

## 01E1-4. 递推方程
T(n)=T(n-1)+1
利用T(n)-n=T(n-1)-(n-1)=...=T(1)-1=T(0)-0
得到T(n)=n+T(0)=n+O(1)=O(n)

## 01E1-5. 数组倒置
```
void reverse(int* A, int le, int ri) {
	if (le < ri) {
		swap(A[le], A[ri]);
		reverse(A, le + 1, ri-1);
	}
}
```
偶数：
	T(n)-n=T(n-2)-(n-2)=...=T(2)-2=T(0)-0
	T(n)=n+T(0)=n+O(1)=O(n)
奇数：
	T(n)-n=T(n-2)-(n-2)=...=T(1)-1
	T(n)=T(1)+1+n=n+O(2)=O(n)


## 01E2-1. 分而治之
![[Pasted image 20240709160833.png]]

## 01E2-2. 二分递归：数组求和
![[Pasted image 20240709161018.png]]
法1，递归跟踪
![[Pasted image 20240709161359.png]]
事实上直接看最后就行了，就是n个
法2，递推方程
T(n)=2* T(n/2)+O(1)
...


## 01E2-3. 大师定理/主定理/Master Theorem
![[Pasted image 20240709161721.png]]
![[Pasted image 20240709162212.png]]


## 01F1-1. 动态规划
在利用递归计算斐波那契数列的时候，到了40多项就寄了
```
/******************************************************************************************
 * Data Structures in C++
 * ISBN: 7-302-33064-6 & 7-302-33065-3 & 7-302-29652-2 & 7-302-26883-3
 * Junhui DENG, deng@tsinghua.edu.cn
 * Computer Science & Technology, Tsinghua University
 * Copyright (c) 2003-2024.
 ******************************************************************************************/

__int64 fib ( int n, __int64& prev ) { //计算Fibonacci数列第n项（线性递归版）：入口形式fib(n, prev)
   if ( 0 == n ) //若到达递归基，则
      { prev = 1; return 0; } //直接取值：fib(-1) = 1, fib(0) = 0
   else { //否则
      __int64 prevPrev; prev = fib ( n - 1, prevPrev ); //递归计算前两项
      return prevPrev + prev; //其和即为正解
   }
} //用辅助变量记录前一项，返回数列的当前项，O(n)
```


## 01F1-2. Fib()：递推方程
F(n) = (1 + √5)ⁿ - (1 - √5)ⁿ / 5
事实上，O(n)=(2^n)

## 01F1-3. Fib()：封底估算
![[Pasted image 20240709171812.png]]

## 01F1-4. Fib()：递归跟踪
斐波那契数列如此计算低效的原因是大量重复的实例，所以要通过这个某种算法去消除！

## 01F1-5. Fib()：迭代
解1：
制作表
解2：
==动态规划==，从自顶向下改为自顶而上！
```
#include<iostream>
using namespace std;

int fabin_kinghua(int n) {
	int a = 0, b = 1;
	while (n--) {
		b = b + a;
		a = b - a;
	}
	return b;
}

int fabin_mine(int n) {
	int a = 0, b = 1;
	int c = 0;
	while(n--){
		c = a + b;
		a = b;
		b = c;
		
	}
	return c;
}


int main() {
	cout << fabin_mine(5) << endl;
	cout << fabin_kinghua(5) << endl;
	return 0;
}

```



## 01F2-1. LCS：最长公共子序列
![[Pasted image 20240709204923.png]]

## 01F2-2. LCS：递归
递归的思路：
对于序列A[0,n]和B[0,m]，LCS有三种情况
1. 递归基，n=-1或m=-1当为空序列的时候，长度为0，返回
2. 假设末尾相同，那么向前移一位，递归求解
3. 假设末尾不相同，那么分成两种情况：
	 1. A序列向前移动一位，但是B序列不动，然后再进行分析
	 2. B序列向前移动一位，但是A序列不懂，然后再进行分析

## 01F2-3. LCS：理解
类似于地图！
![[Pasted image 20240709211905.png]]

## 01F2-4. LCS：复杂度
![[Pasted image 20240709212405.png]]

## 01F2-5. LCS：动态规划

从逆过程，然后填表
![[Pasted image 20240709212747.png]]



[递归解决最长公共子序列问题（LCS）_最长公共子序列 递归-CSDN博客](https://blog.csdn.net/qq799028706/article/details/73008992)

```
#include<iostream>
using namespace std;
string a, b;

int LCS(int m, int n) {
    if (m == a.length() || n == b.length())
        return 0;
    if (a[m] == b[n])
        return LCS(m + 1, n + 1) + 1;
    if (a[m] != b[n])
        return max(LCS(m, n + 1), LCS(m + 1, n));
}

int main() {
    a = "didacticA";
    b = "advantA";
    cout << LCS(0, 0) << endl;
}
```



# 第二章向量
## 02A1. 接口与实现
抽象数据类型？
数据结构？

线性序列：向量；链表

注意两个：
	ADT，抽象数据类型
	DS，数据结构

## 02A2-1. 向量ADT
数组事实上就是一组连续的数据空间
下标唯一，A[i]=A+i×s

而向量，个元素与[0,n)的秩一一对应。
元元素的类型不限于基本类型，因为已经封装了，所以便捷地......

![[Pasted image 20240710101805.png]]

==注意以上是它自己给的模板类，我打算到时候直接去学stl去了，这里康康就行
当然回头还是要来研究一下具体的代码实现的，我这块还是比较薄弱的==

## 02A2-2. 接口操作实例
空向量
上述规范事实上就是说明书，暂时并不需要了解具体功能



## 02A3-1. 构造与析构
这里采用的是他自己写的构造和析构函数，我感觉已经可以根据他的这个进程然后直接自己去学stl了


## 02A3-2. 复制

例如一串向量的长度从0到n，我需要从中复制a到b，这里的思路是：
搞一个新的向量长度从0开始，然后让原向量的a位置等于现在的0位置，依次复制过去就行了

-----------
上面那块还有点没看懂，目前看来这个向量类应该是他自己写的，所以到时候如果使用stl地话还得去学stl的语法，待会儿可以问一下备考小升初那位
确实如此


## 02B1-1. 可扩充向量
因为目前采取的策略仍然是静态策略，也就是向量所占用的空间事实上是一个静态的水平，有可能会发生上溢或者下溢，
在实际的使用过程中，我们难以准确预测实际所需要的空间需求量所以我们需要采取策略来克服这种情况，即==动态调整==

## 02B1-2. 动态空间管理
这个方案并非最好 ，但是可以作为改进的起点
事实上很简单可以想到一种思路，就是当内存不够的时候，换一个内存条，把原来所有的东西都复制粘贴到新内存条，然后把原来的内存给释放掉
我感觉这里其实和翁恺的当时讲malloc的时候有点类似，思想上是差不多的
以下是两种思想

## 02B1-3. 递增式扩容
第一种思想是在内存到的时候进行常数级别的扩容，事实上就是从固定一个长度a，然后每当快要到达的时候，换一个内存条，这个内存条比原来的内存条长a
其平均复杂度为O(n^2)，计算如下：
事实上其为一个算术级数，计算完毕
对于单次扩容的时间复杂度是
![[Pasted image 20240710115537.png]]
## 02B1-4. 加倍式扩容
第二种思想就是在内存到的时候讲内存长度进行一次左移操作，即将内存条翻倍
其为一个几何级数，所以时间复杂度为O(n)
事实上这里需要注意的是，这里并非每次操作都要进行扩容，其扩容一次后所需要达到下一个扩容的时间长度也是几何级数，所以并非O(2^n)之类，
那么对于单次扩容的时间复杂度是O(1)，为何？
![[Pasted image 20240710115549.png]]

## 02B2.分摊复杂度
对比以上两种的算法，可以很明显地看出，递增是扩容事实上是
![[Pasted image 20240710114534.png]]

可能可以这么理解吧，在计算每一个复杂度的单个步骤的时候的那个通解，在递增单词通项式的时候是O(n)，而在加倍扩容的时候是O(1)，因为后者是在确定次数的时候扩容==（可能是这么理解的吧，回头再来看看）==

注意这里其实我没看懂......分摊复杂度和平均复杂度这里的计算
-------



## C. 无序向量

## 02C1-1. 概述
无序向量，如何定义并实现操作接口
## 02C1-2. 循秩访问
这一块直接看看思想，然后待会儿花点时间学一下vector的stl
事实上通过各种接口就可以直接去搞，但是看不懂，比较难理解，所以可以直接进行重载
比如说A[1]，然后重载[]
通过秩去访问

## 02C1-3. 插入
如何插入新的元素？
思路大概是先检查是否满了，满了就扩容
利用从后向前复制，最后把新增加的放在第一个里面，这个感觉可以自己写一下
扩容暂且先不管
```
#include<iostream>
using namespace std;


void myinsert(int arr[],int num,int n) {
	for (int i = n;i > 0;i--) {
		arr[i] = arr[i-1];
	}
	arr[0] = num;
}


void test01() {
	int arr[10] = { 1,2,3,4,5,6,7,8,9 };
	myinsert(arr,10,9);
	for (int i = 0;i < 10;i++) {
		cout << arr[i] << endl;
	}
}

int main() {
	test01();
	return 0;
}
```

简单写了一个

## 02C1-4. 区间删除
注意要从前元素向后元素的位置复制，和上面的例子完全相反，否则会产生覆盖，从而导致复制错误
还需要进行多余的区间删除，不过在实际的应用中并不常见

## 02C1-5. 单元素删除
可以视为前者的特例，调用区间删除接口
但是为什么不能反过来？调用单元素删除接口来完成区间删除接口呢？
我认为是和上面的原因一样，可能会造成元素从而导致的复制错......
==好吧我的是错的==
因为这种方法效率很慢，复杂度应该是O(n^2)

## 02C2. 查找
按照某种条件，查找向量中的元素
思路：最重要的是while循环，从后向前检索
最好O(1)，最差O(n)，输入敏感！！！
和输入的数据紧密相关

## 02C3. 去重/唯一化

==大概的思路如下：（理解错误！！）
首先先选定一个位置作为初始（通常为刚开始的地方），然后自前向后进行比较，如果有相同的那么就删去，并且计数+1，如果没有的话就进行下一个，直到到了末尾为止。如果返回的是一个正数，那么就证明是有雷同项的，如果返回的是非法值，那么就说明没有雷同项==

大概思路如下，选定第1项arr[1]，然后进行对前面序列的比较，如果前面的序列有重复的， 那么就剔除自己本身，后面序列向前移动；如果没有重复的，那么向后移动一项，然后继续比较前面的序列，直到遍历了整个数组。
时间复杂度是O(n^2)
有两个操作，一个是检查前面，另一个是遍历。

==这里有一个作业我没有看，注意一下，是将这个算法改进为O(nlogn)==

![[Pasted image 20240710191853.png]]

## 02C4. 遍历
![[Pasted image 20240710191832.png]]

## 有序向量
## 02D1-1. 有序性
无序向量可以进行的操作是比对，比方说disordered()，可以判断整个数组中有多少个逆序对，从而判断这个算法中乱序的程度
有序向量可以进行的操作是比较，那么为什么将无序向量转换为有序向量呢？
虽然将无序向量转换为有序向量需要一定的时间，但是此后更多的操作，例如删除相同元素等的一系列操作相比，花费时间将无序向量转换为有序向量还是很值得的！

## 02D1-2. 唯一化（低效版）
有序向量剔除相同元素的方法和我先前想的是一样的，就是从第一个开始和后面那个进行比对，遇到相同的就删掉，遇到不同的就跳一个，然后那个再和下一个进行比对，我个人认为其复杂度凭感觉是O(n^2)（最坏情况）

## 02D1-3. 复杂度（低效版）
正是和我上面说的那样，甚至这个的时间复杂度和无序的算法是一样的！

## 02D1-4. 唯一化（高效版）
造成这个的原因是一次移动，如果能够多次移动呢？
和蛮前面那个例子是一样的！就是删除某个区间的例子！
但是这里有一个写着的，不能用先前的remove成批删除，是因为remove事实上也是一个O(n)的算法，如果使用了的话和前面是一样的，如果只是利用最基本的检索和删除的话，复杂度......
==我上面说的这些其实是有点问题的==
## 02D1-5. 实例与分析（高效版）
这里的思路应该是比较，然后将不相同的复制到另一个相邻的那里，到了最后的时候只要更改一下区间删除罢了！！！！
累计是O(n)


## 02D2-1. 二分查找！！概述

查找！

## 02D2-2. 接口
fibSearch斐波那契算法
binSerch二分查找法
这里需要解决很多特殊情况，比如说相同的元素，或者元素不存在等


## 02D2-3. 语义
其采用的是他自己的接口，待会儿回去看看

---------



## 02D2-4. 原理
二分查找的原理事实上就是把查找点刚开始设置在重点，然后去比较，新的问题总是老问题规模的一半，即减而治之，减掉一半

## 02D2-5. 实现
具体实现
```
int mybinSearch(int arr[], int le, int ri,int re) {
	while (le < ri) {
		int mi = (le + ri) >> 1;
		if (re < arr[mi]) {
			ri = mi;
		}
		else if (arr[mi] < re) {
			le = mi+1;
		}
		else {
			return mi;
		}
	}
	return EOF;
	//注意左闭右开！！
}
```


## 02D2-6. 实例

复杂度为O(logn)
因为每次问题的规模减半，可以理解为原来的位数右移一次，所以原来的复杂度取决于原来长度的二进制的位数！

## 02D2-7. 查找长度
查找长度，实际上就是代码比较的次数
从成功，失败，最好，最快，平均等进行评估

成功，失败时的平均查找长度差不多都是O(1.5logn)

例如比较
![[Pasted image 20240710213134.png]]


```
#include<iostream>
using namespace std;

int mybinSearch01(int arr[], int le, int ri, int re) {
	int cnt = 0;
	while (le < ri) {
		int mi = (le + ri) >> 1;
		if (re < arr[mi]) {
			ri = mi;
			cnt++;
		}
		else if (arr[mi] < re) {
			le = mi + 1;
			cnt += 2;
		}
		else {
			cnt += 2;
			break;
		}
	}
	return cnt;
}

int main() {
	int V1[] = { 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61 };
	int V2[] = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18 };
	cout << mybinSearch01(V1, 0, 17, 43) << endl;
	cout << mybinSearch01(V2,0, 17, 14) << endl;
	int V[] = { 2, 3, 5, 7, 11, 13, 17 };
	cout << mybinSearch01(V1, 0, 7, 16);
	return 0;

}
```

为了解决而自己搞得一个计算cnt的程序，可以计算出到底用了多少步

另外，注意其提供的search函数，是返回不超过提供数的最大的秩，所以在插入的时候应当+1
应该是这样理解的


## 斐波那契！！

## 02D3-1. 构思

按照上面的思路，看似十分平衡，但是事实上向左转消耗地比右侧地少一点
所以有一个思路就是让左边的多做一些，让右边的少做一些 。
我们利用斐波那契数，假设一个长度是第k个斐波那契数-1，那么选择一个特定的切分点，
即第k-1个斐波那契数-1，这样左边的长度就是第k-1个斐波那契数-1，右边的长度就是第k-2个斐波那契数-1；

## 02D3-2. 实现

事实上，斐波那契查找的大体思路和二分查找是完全一致的，区别只是在middle点的选择上！

## 02D3-3. 实例
通过计算，我们可以知道斐波那契查找下，查找成功的平均值和查找失败的平均值均略优于二分查找

## 02D3-4. 最优性
事实上斐波那契算法已经是该算法的最优解了，即O(1.44n)，无法再进行更优的改进，如果想要改进的话则必须采用更好的算法思路

以下是自己编写的斐波那契查找法


## 二分查找B
## 02D4-1. 构思
因为有轴点，所以很必须进行三个分支，那么改成两个分支呢？
也就是说，将轴点的情况归结到右侧那个分支上去！
然而此时的判定方法就是当区间长度=1时进行判断就可以了

## 02D4-2. 版本B
```
#include<iostream>
using namespace std;

int myn2bisearch(int arr[], int lo, int hi, int e) {
	int mi ;//保证mi有定义
	while (1 < hi - lo) {
		mi = (hi - lo) >> 1;
		e < arr[mi] ? hi = mi : lo = mi;
	}
	return arr[mi] == e ? mi : EOF;
}


void test01() {
	int arr[10] = { 1,2,3,4,5,6,7,8,9,10 };
	cout << myn2bisearch(arr, 0, 9, 2);
}

int main() {
	test01();
	return 0;
}
```
平均情况更好，最好的情况更坏，但是最坏的情况更好！

## 02D4-3. 语义
事实上无论是本次的二分查找以及上述的A版本，都没有对返回值做出很好的处理，我们需要返回的是不大于该元素的最后一个元素
这样我们可以进行对向量本身的维护，例如在插入一个数值时，保证其仍然是按照顺序的

## 二分查找C

## 02D5-1. 版本C
版本c其实我有点没太看明白，

---------
==每太看明白，先过==




## 02D6-1. 插值查找原理
假设不仅仅是按照顺序的
而且还拥有某种特殊的分布
简单来说其实类似于查英文字典，我们人在进行查字典的时候肯定，例如我现在要查询apple这个单词，那么我肯定不会向后去查找，而是在前1/26大概去查找。类似的，比如说我想去找一个单词search，我肯定也不会在前面查找，而是向后去看，向后查找。
所以的话，很简单的道理，如果在进行查找的时候并不是机械地去这样找，而是按照一种动态地方式去确定分点从而进行查找的话，那么效率肯定会提升非常多。

其选取mi点的公式为：
mi ≈ lo + (hi-lo) * (e-A[lo]) / (A[hi]-A[lo])；

这是一种动态的查找
## 02D6-2. 实例
虽然其可以迅速地缩减范围，但当数据分布并是均匀独立的时候，其往往会陷入到陷阱之中

## 02D6-3.性能分析
**平均情况：每经一次比较，n缩减$\sqrt{n}$**
即根号嵌套n
收敛地非常非常快

## 02D6-4.字宽折半
以下是估算法：
这里我们采用二进制的思想，一个数据n，取二次根，而其长度logn，变成了原来的二分之一。
所以插值查找就是对n的二进制宽度进行二分查找！！



## 02D6-5.综合对比
事实上，我们不应当将目光局限于某一个单一的算法，而应该综合对比。
尽管插值查找的复杂度是O(loglogn)，可以在宏观的范围内迅速缩小，但是其却非常容易掉入某种陷阱，从而花费更多的时间。而且其还运用了乘除法，更消耗时间
二分查找或者此前的斐波那契查找的复杂度是O(logn)
最简单的顺序查找的复杂度是O(n)
综上所述，我们可以得到如下的结论。
我们在解决一个问题的时候：
当在一个宏观的范围进行搜查时，我们应当调用的是插值查找；
当范围缩小到一定的范围，即中等范围时，我们考虑使用二分查找；
当问题的规模缩小到足够小时使用顺序查找。
综合使用此前介绍的所有方式，才可能在实际的运用中取得最好的效果！！




## 02E1-1.冒泡排序构思
因为有序向量的查找比无序向量的查找快多了，所以要进行排序。
原始版本的冒泡排序就是扫描交换
因为我们做了重复的工作！！
事实上我们只需要记录每次扫描的时候做的交换次数，如果为0，那么就证明这个向量已经是排序号的了！！

## 02E1-2. 改进
以下为代码实现
```
#include<iostream>
using namespace std;

void swap(int& a, int& b) {
	int t;
	t = a;
	a = b;
	b = t;
}

void mybubbleSort(int arr[], int n) {
	for (int i = 0;i < n - 1;i++) {
		bool haha = false;
		for (int j = 0;j < n - i - 1;j++) {
			if (arr[j] > arr[j + 1]) {
				swap(arr[j], arr[j + 1]);
				haha = true;
			}
		}
		if (haha == false) {
			break;
		}
	}
}

void test01() {
	int arr[10] = { 1,4,5,7,9,10,11,45,67,90 };
	mybubbleSort(arr, 10);
	for (int i = 0;i < 10;i++) {
		cout << arr[i] << endl;
	}
}

int main() {
	test01();
	return 0;
}
```
我感觉我的没啥问题

事实上正常的冒泡排序可以理解为一个三角形，这个版本可以理解为一个梯形！

不过依旧可以进行改进？

## 02E1-3.反例
有一个反例是这样子的：
如果有一个形如下面的向量：
{3，4，2，1，5，6，7，8，9，10，11，......}
可以观察到，除了前四项不是排序好的之外，剩下的所有项都是排序好的。
但是其会一直检测到最后一项为止，并且确认最后一项是ok的，并且返回并非完全排序。
在这之中仍然浪费了很多的时间。
所以我们的思想是是否有一种算法可以使得忽略到后面的情况？直接在对前面四项进行排序？
==在计算复杂度那里我没看太懂==

## 02E1-4.再改进
事实上只用改变区间长度就可以了，那么我们来进行调试：
```
#include<iostream>
using namespace std;

void swap(int& a, int& b) {
	int t;
	t = a;
	a = b;
	b = t;
}

void mybubbleSort(int arr[], int n) {
	for (int i = 0;i < n - 1;i++) {
		bool sort = false;
		int last = -1;
		for (int j = 0;j < n - i - 1;j++) {
			if (arr[j] > arr[j + 1]) {
				swap(arr[j], arr[j + 1]);
				sort = true;
				last = j;
			}
		}
		if (sort == false) {
			break;
		}
		if (last != -1) {
			i = n - last - 2;
		}
	}
}
//去动i

void test01() {
	int arr[10] = { 16, 59, 38, 71, 93, 26, 47, 82, 64, 100 };
	mybubbleSort(arr, 10);
	for (int i = 0;i < 10;i++) {
		cout << arr[i] << endl;
	}
}

int main() {
	test01();
	return 0;
}
```
这样应该是没问题了

但无论如何其只是起泡排序，始终是O(n^2)

## 02E1-5.综合评价
1.三种算法O是一样的，最好是O(n)，最坏是O(n^2)
2.冒泡算法是稳定的，不会改变相同元素的次序


单选题 (1分)

Try the following algorithm to sort V={19, 17, 23}: 试用以下算法对V={19, 17, 23}排序：

1. Sort by units at first 1. 先按个位排序

2. On the basis of the previous step, sort again by tens 2. 在上一步基础上，再按十位排序

Is this algorithm correct? 这个算法的是否正确？

A Certainly correct 一定正确

B Certainly incorrect 一定不正确

C If the sorting algorithm used in step 2 is stable, then correct 若第2步用的排序算法是稳定的，则正确

D If the sorting algorithm used in step 1 is stable, then correct 若第1步用的排序算法是稳定的，则正确



## 02F1-1. 归并排序：构思
merge_sort
比较排序的算法，下届都是O(logn)
寻找一个算法，在最差的也是O(logn)
思路：
1. 将序列一分为二
2. 子序列递归排序
3. 合并有序子序列

## 02F1-2. 归并排序：主算法
思路其实就是先处理递归基，然后取重点，随后排序lo, mi；mi, hi，最后进行合并


## 02F2-1. 二路归并：实例
归并的原理：
![[Pasted image 20240713135017.png]]
如果是一样的，那么随便选取一个
我们的归并排序事实上是来源于一个更大的...
## 02F2-2. 二路归并：实现
事实上这里我还没有太理解...



--------


# 第三章、列表
## 03A. 循秩访问
因为列表的存储在空间中是不连续的，所以我们可以对[]进行重载，这样的话，我们可以很容易地去判断每个列表结点地位置。
但是这种效率十分低下，我们可以容易知道如果采用这个方法遍历这个列表的话，时间复杂度O(n^2)，如果我要查询某一个结点的话，那么时间复杂度就是O(n^2/n)
所以访问某一个结点的时间复杂度是O(n)，这是一种很低效的方法，我们并不经常用。
因此我们引入一个概念，从静态到动态！

## 接口和实现
## 03B-1. 从静态到动态
静态：仅读写
动态：需写入
因为向量对动态的操作非常麻烦，例如要全部向后移动一格，所需要的时间复杂度是O(n)，所以的话我们如果考虑用列表去实现的话，肯定会方便很多

## 03B-2. 从向量到列表
线性结构，在逻辑上构成一个线性序列
没有前驱和后继的分别是首结点和末结点
并不在空间上连续

## 03B-3. 从秩到位置
向量支持寻秩访问，根据数据元素的秩，可以在O(1)的时间内找到物理位置
链表也存在秩，可以从头出发，寻找......
但此时用寻秩访问的方式时间成本很高，并不是常数
此时，我们应改用，循位置访问！
应该转而利用节点之间的相互引用 ，找到特定的节点

## 03B-4. 实现

这边只要注意一下它这边有四个概念，头元素，首节点，末节点，尾元素
两个哨兵是不可见的！！（头元素，和尾元素）

## 无序列表！
## 03C1. 插入与构造

关于插入如下：

插入的话很简单，整个过程只涉及到两三个节点，即要插入的那个节点，要插入的那个节点的前一个结点以及后一个结点，思路其实也很简单，我们假设结点c要插入结点a和b之间，只需要让结点a的后继变成结点c的前驱，结点b的前驱变成结点c的后继，这样子就完成了一次插入操作

如果这个结点是首结点或者末结点，但是事实上在内部还有头节点和尾结点，所以进行上述操作不会有任何问题。

## 03C2. 删除与析构

事实上删除可以表述如下：

我们假设在逻辑上有连续的三个结点a，c，b，现在我们要将c给去掉，只要将c的前驱的后继变成c后继，将c后继的前驱变成c前驱，然后将c给delete掉，这是常数级的

如何析构呢？

先将对外可见的全都析构，然后再将两个哨兵给删除。事实上只需要反复删除头元素的后继就行了

## 03C3-1. 查找

采用的是他给的接口find(e,n,p)

无序列表的查找算法：

在当前这个链表中，以p结点为基础，然后逐步向前比对，一旦发现命中，随即返回，如果整个迭代步数n已经耗尽，那么在这个区间里不存在......注意返回的是结点的位置。如果有多个，那么就会返回距离p最近的那个，符合语义。事实上时间复杂度就是O(n)，最坏的情况下需要遍历n。

如果我们调换n和p的位置将接口改为find(e,p,n)，那么就会变成从p的后一个开始向后查找n个，与上面那个相反

注意返回值，如果找到了返回该元素的位置，如果没找到那么返回空

## 03C3-2. 去重

如何去重？

首先确认这个链表至少含有两个结点，然后让刚开始指向首结点，每次都向前查找p的真前驱。如果找到了，那么就删除此前那个元素，如果没找到，那么就向后一个单位。

删除前面那个元素更保险一点，删除本身会有危险


==注意我还得多去看点链表的源码==

## 有序链表
## 03D1-1. 唯一化-构思

可以仿照数组进行唯一化，即使用remove，一个一个雷同结点地删除

## 03D1-2. 唯一化-实现

和向量一个思路，遍历，看相邻，如果相邻相等，那么调用remove接口，如果没有，那么转移到下一个，直到试图越界

## 03D2. 查找

如何查找呢？

让p开始，然后向前比较，一旦发现一个不大于的就返回，最好O(1)，最坏O(n)，和无序列表其实差不读。

==我们现在来比较一下向量和链表的方式

==向量采用的是寻秩访问的模式，即只要一个给定的rank，都能在O(1)的时间内找到这个的位置，和最开始绪论中说的RAM模型类似

==而链表采用的是寻位置访问的模式，类似图灵机模型，虽然长度无限，但是每次只能操作一个单位，向左或者向右

注意有序链表和无序链表的去重模式，前者是和向量最开始的那个一样，保留相同元素的首元素，而后者是固定本身向前查找并且删除前者


## 03E1-1. 选择排序构思 selection_sort

从中找出最大的，然后拿出来放到外面去

对比一下bubblesort，bubblesort是进行一次一次的交换，让最大的值以短跑式的跃动到达的，而selectionsort直接找出最大值移动到该有的位置，更加高效

## 03E1-2. 实例

分成两部分，Usorted and sorted

只是从交换次数上讲，seletionsort会比bubblesort高效一些

## 03E1-3. 实现

思路其实很简单，固定首结点，然后向数n个，找出最大的，删除，然后把这个结点接到最后，n-1，随后进行更多操作......

## 03E1-4. 推敲

事实上，有两个很重要的点如下：

1. 如果碰到了右边的情况{3,5,2,2,2,2,1,4}，在对2进行操作的时候会有多次操作，能否避免？（实际上得不偿失）
2. new和delete的动态操作是正常操作时间单位1的100倍，所以我们要尽可能地去避免，我们其实可以直接交换两个的数据，而并不交换他们的链表结点位置，和向量似的，向量正是只交换了他们的数据，而并没有交换他们的地址！

## 03E1-5. selectMax()

思路很简单，其实就是从首元素开始向后找，然后找到一个最大的并且返回

painter's algorithm

就有点像画油画，取最后

比较器选择>=，能保证算法的稳定性

## 03E1-6. 性能

O(n^2)

尽管如此，但是元素移动的操作远远少于起泡排序O(n^2)主要来自于比较操作，在后续章节，借助精巧的数据结构，可以使selectMax()在O(logn)的时间内完成

## 插入排序03G1-1. 经验

其实类似于整理扑克牌或者麻将那样

## 03G1-2. 构思

前缀长度为r视为sorted，后缀为n-r为unsorted

然后进行迭代，选择当前秩为r的“牌”，插入到已经排好的牌那里，然后插入进去，如此进行之后，排序就完成了

## 03G1-3. 对比

与selectionsort相比，他们截然不同。

在策略上的不同：有序和无序部分前缀和后缀相反，且在插入排序中，后缀与前缀毫无关联，而在选择排序中，前缀必然是小于等于后缀的最小值的！！

## 03G1-4. 实例

刚开始是空串，然后把注意力放在未排序的首元素上，然后对比，插入到有序部分

## 03G1-5. 实现

其实就是锁定一个元然后按照上面的方法进行迭代

## 03G1-6. 性能分析

最好情况就是O(n)，而最坏情况就是每次都需要比较，就是O(n^2)，事实上这里的时间复杂度来源于进行比较所花费的时间，所以我们可以考虑在插入的时候为什么不使用我们此前所介绍过的二分查找呢？

很简单，其一是因为链表无法使用二分查找，即便是改变为向量，但是进行二分查找后，向量无法像链表那样方便地插入，而是需要逐一向后移动，从而产生更多的时间

## 03G1-7. 平均性能

计算数学期望并分析可知，在平均情况下，复杂度也是O(n^2)

## 03G1-8. 逆序对

逆序对，顾名思义就是12354678，此处{5，4}即为一个逆序对，可以知道在一个长度为n的序列中，逆序对的数量最多为(n+1)n/2

对比上述的插入排序，我们可以知道，事实上我们需要进行I次比较，I即为逆序对的数量，所以该算法的时间复杂度就是O(n+I)

当在最好情况的时候，I=0，此时时间复杂度就是O(n)，当情况最坏的时候，I=(n+1)n/2，此时时间复杂度即为O(n^2)

从上面我们可以知道，该算法的复杂度均来源于比较，而与选择排序不同的是，选择排序必须得一个个比较过去，没有所谓的优化，而插入排序的比较次数却取决于当前需要进行插入的数据，所以这里引出一个概念叫做敏感的，这个算法对数据的输入较为敏感，对此后希尔排序的学习做了铺垫


---

在学这一整章的时候我没有很注重代码，也就是链表的代码，毕竟这是他给的接口，等把stl过一遍之后，回头用stl提供的列表来写一遍这个




# 第四章、栈

## 04A1-1. 栈

stack，只能访问的称为顶端，另一端不开放的称之为盲端。举一个很简单的例子，就是摞椅子，只能从最上面搬走，或者从最上面插入

push，即压入；pop，即取出；top，只查询顶部的数值

## 04A1-2. 实例

Last in, first out，即LIFO

empty()，返回true或者false

## 04A1-3. 实现

栈结构应该如何实现？栈结构事实上是一种受限的线性序列，即可以通过向量或者列表直接模拟栈

## B不见了？

## 04C1-1. 应用

大体可以变成以下四类：

其一：逆序输出；其二：递归嵌套；其三：延迟缓冲；其四：栈式计算

## 04C1-2. 算法

对于第一类，考虑进制转换

比如说把89变成2进制的数字，因为无法直接确认第一位是什么，如下，最后逆序输出

![[Pasted image 20240716140335.png]]

如何将2013转换为五进制下对应的表示？

2013    3
402      2
80        0
16        1
3          3
0

最后变成31023

## 04C1-3. 实现

一样，因为他用的是自己的接口，所以等学完stl之后回头来写一下

思路是在计算的时候通过while循环进行压入，然后再通过pop输出，注意一个快捷就是while(!empty)，差不多是这个东西

## 04D1-1. 实例，括号匹配

可以归咎于递归嵌套，具有自相似的特性，即局部和整体具有类似性，但是在经过具体计算之前很难进行分支和位置定位，分支和嵌套深度并不固定

## 04D1-2. 尝试

先扫描一遍进行预处理，即把除了括号之外的所有符号都去除掉

然后我们就考虑到了此前的处理方式，即分而治之以及减而治之，但很快我们就能找到反例这样的作法是行不通的

## 04D1-3. 构思

颠倒思路，减而知之的思路是从外面消除从而走向里面，如果反过来从里往外走的话是不是就可以，并且如何找到一种办法持续下去呢？

实时处理！！

思路很简单，就是利用栈，让左边的括号入栈，即栈内只有“（”，匹配下一个元素，如果是“（”，那么就入栈，并且检查下一个；如果是“）”，那么就让栈内的元素出栈一个即可。如果在还有待检测元素并且栈为空或者栈内仍有元素但是没有待检测元素，这两种情况都是括号不匹配，反之，如果监测到最后栈为空也没有待检测元素了，那么括号就是匹配的！！！

## 04D1-4. 实现

和上述一样，学完stl之后来写一遍

## 04D1-5. 反思

为什么要使用栈呢？其实只要设置一个简单的计数器，当遇到左括号时+1，遇到右括号时-1，只要计数器最终回到0，那么就是成立的。当然在这个过程中计数器不能变成负数，在最终也不能是非0的数字。这个计数器就是反应的是栈的变化情况，所以为什么不能使用这个计数器呢？
## 04D1-6. 拓展

可以拓展到多个括号的情况，这个时候用计数器就出大问题！

举例：【（】），计数器可以正常工作，但是确实是不成立的！！！

可以再拓展，（）里面的东西也可以进行此类的计算，匹配是否是同种东西！

## 04E1-1. 栈混洗

有三个栈A【 >   ，B< 】。以及中间一个中转栈C，只允许Bpop入C，Cpush入A

## 04E1-2. 计数

对于长度为n的序列，可能得到的栈混洗数量是多少呢？

只考虑第一个元素，如图所示，左边的k-1与右边的n-k是相互独立的栈混洗

![[Pasted image 20240716151805.png]]

catalan(n)=(2n)!/((n+1)!n!)

## 04E1-3. 甄别

事实上有一个很简单的例子，例如B<1，2，3】，那么A必然不可能为【3，1，2>，很简单，因为为了获取3让其成为最后一个元素，那么必须要把所有的元素弹出之后然后再进行压入，从而自然地进行3->2->1的操作。

也就是说，对于任何1<=i<j<k<=n，只要出现k，i，j的形式，那么就不是栈混洗，反之亦然

## 04E1-4.算法

依旧是学完栈的stl之后来写。

对于如何判断该栈是否是通过栈混洗得到的，有以下三种思路：

1. O(n^3)，选取三个i, j, k，直接进行模拟
2. O(n^2)，选取三个元素分别为i, j, j+1，直接进行模拟
3. O(n)，模拟，通过栈的压入与弹出看看能否最终达成该栈，如果可以，那么就是栈混洗，如果不行，那么就不是栈混洗

## 04E1-5. 括号

回头看看括号匹配

![[Pasted image 20240716151358.png]]

压入和弹出，恰好是一对括号！

也可以解释为栈混洗

![[Pasted image 20240716151430.png]]

其为一一对应的关系

## - F. 中缀表达式求值

## 04F1-1. 把玩

不能保证输入和处理同步，必须得保证在预读一定数据之后才能进行处理

例如caculate！我们必须保证在一定的输入之后才能进行有效的计算！

## 04F1-2. 构思

思路如下，利用栈结构将整体分成两大块

扫描了的（扫描了尚未处理的+扫描了已经处理的）；未扫描的

以这样的思路来构筑

## 04F2-1. 算法框架

思路很简单，就是采用一个栈，判断栈顶运算符的优先级与当前运算符的优先级即可，优先级的比较通过列表进行比较。

注意到事实上如果将数字和符号全部放进一个栈内的话，即不直观也不方便，所以可以使用两个栈，一个实现放入数字，一个实现放入符号

## 04F2-2. 算法细节

事实上就是对原来的序列进行扫描，将数字放进A栈中，将运算符放入B栈中，当栈顶元素比当前元素的优先级高的时候，先判断是单目运算符还是双目运算符，随后对数据进行弹出一个或者两个，进行计算后再返回数字栈中

==上述解释有点问题==

在最开始的时候在B栈内放入一个‘\0’，起到标识符的作用，作用事实上和括号类似

上述两节同样是等学完stl之后再回头来写一遍

## 04F3-1-04F3-4. 实例A-D

看完了部分实例，我感觉我上面的解释有问题，应当先定位，定位判断后再入栈或者进行其他操作，否则一直都是在那个位置


代码还是得自己写写，感觉原理啥的都没吃透
--------------------------------------------------------------------------------

## - G. 逆波兰表达式（RPN）

## 04G1-1. 简化

上述的算法逻辑十分地混乱，RPN直接讲式子变成无括号形式，并且使得可以直接从左往右进行计算


## 04G1-2. 体验

高效，简洁！

## 04G2-1. 手工

从中缀表达式到逆波兰表达式

如先取之，必先予之

## 04G2-2. 算法

![[Pasted image 20240718190313.png]]

其实如上就行了，对于操作数而言，直接接入RPN末尾即可，对于操作符，当为>的时候才接入RPN末尾

## - H. 队列ADT及实现（queue）

## 04H1-1. 接口

队列与栈完全对称

队尾，队头

先进先出

## 04H1-2. 实例

接口一样的，学了stl之后再看


## 04H1-3. 实现

与栈同理，属于序列，可以使用向量或列表派生得

用列表或许会更方便一点，如果使用向量的话难搞，向量的话比较适合一端作为盲端

# 第五章、二叉树

注意我上一章练习没写
----------------------------------------

## 05A-1 动机（树）

之前讲的数据结构都是线性结构，向量和列表不够用

对于向量和列表的操作：

![[Pasted image 20240718191703.png]]

向量和列表都无法兼顾搜索和插入删除，如何将二者融合起来呢？

树可以理解为列表的列表List《List》，半线性结构

## 05A-2 应用

文件系统的文件结构，从大学到学院到专业到班级......

树是一种按照层次性的......组成的数据结构

## 05A-3 有根树

从数学方面，树结构可以是一种特殊的图

对于树来说，引入一个顶点（注意和列表中的顶点有差别），即有根树，有根树可以通过一个新的root，形成一个更大的有根树

## 05A-4 有序树

ri是r的孩子们，r是ri的父亲，d是r拥有的孩子的数量，称之为度

而ri互相之间为兄弟，而如何确认ri的兄弟关系呢？需要对ri进行编号，如果有编号了，那么就是有序树

一棵树所对应的边数e=所有顶点度数之和=顶点总数n-1，即边数和定点数是等阶的！所以在计算时间复杂度时，使用n来确定O

## 05A-5 路径+环路

通路：在V中的k+1个节点，通过k条边连城一条路径

![[Pasted image 20240718193138.png]]

路径长度=边数=k

如果k连上了0，在拓扑上构成循环，所以称之为环路

## 05A-6 连通+无环

![[Pasted image 20240718193717.png]]

树是一种无环连通图，其是极小连通图，也是最大无环图，既要保证边的数量足够以达到可以联通起每一个结点，但是也要确保边的数量不能太多从而引起形成环路

## 05A-7 深度+层次

通往根的路径是唯一的

![[Pasted image 20240718194131.png]]

祖先唯一但是后代不唯一，但是对于链表和向量来说，二者中的任何一个元素都有唯一的前驱和后继

没有后代的节点称之为叶子


## 05B-1 表示法

树的表示：

![[Pasted image 20240831095125.png]]

这个得手撕源码了！

父亲+孩子法 父亲，后面是孩子的引用，还后面串着孩子
长子+兄弟法（可以将任何树转换为二叉树！）
父亲只关注自己的长子，长子将兄弟作为自己的右孩子，


firstChild()
nextSibling()



## C.二叉树



binnode

![[Pasted image 20240831102447.png]]


然后就是二叉树的各种实现，我感觉理解起来有很大的问题！


树的这部分没做什么笔记，但是大概听懂是什么意思了。

首先是栈结构，无论是先序遍历、中序遍历还是后序遍历都需要栈结构

然后是先序遍历，先序遍历借助栈，visitalongleftbrunch，访问后将右孩子推入栈中
然后是中序遍历，goalongleftbrunch
将之推入栈中，没有了之后推出并且将控制权转交给右孩子，从而继续
而层次遍历则是利用队列，推入队列后左顾右盼，等到没有了再访问出队列，就行了。

后面就是根据遍历重构树。思路都是利用递归，分而治之，找到根，找到左子树找到右子树，从而将问题分而治之。

代码部分还是要注意一下，我现在根本都不知道怎么实现代码（）




# 第六章 图

这里开始只看ppt（自从更新这个文档已经过去了三个多月......）

图分为有向图，无向图，加权图等，可以用邻接矩阵，即一个二维向量实现
顶点集

图可定义为G=(V , E)
v为顶点，e为边，均为有限集

### 6.b1 邻接矩阵


